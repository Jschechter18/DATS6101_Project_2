---
title: "Tree Model"
author: "Josh Schechter"
date: "2025-04-22"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(dplyr)
library(readr)
library(ggplot2)
library(tidyr)
library(caret)
library(rpart)
```

```{r}
students <- read.csv("../data/Students_Grading_Dataset_Cleaned.csv")
```

```{r}
set.seed(1)
tree_model <- rpart(Pass_Fail ~ Attendance + Family_Income_Level, data=students, method="class", control = list(maxdepth = 4) )
```

```{r}
summary(tree_model) # detailed summary of splits
# plot tree 
plot(tree_model, uniform=TRUE, main="Classification Tree for Attendance")
text(tree_model, use.n=TRUE, all=TRUE, cex=.8)
```
## Random Forest Model
```{r}
library(randomForest)

students$Pass_Fail <- as.factor(students$Pass_Fail)

# Building random forest model
set.seed(1)
rf_model <- randomForest(Pass_Fail ~ Attendance + Family_Income_Level + Extracurricular_Activities + Internet_Access_at_Home,
                         data = students,
                         ntree = 500,
                         mtry = 2,
                         importance = TRUE)

print(rf_model)
```
## Prediction and confusion matrix
```{r}
rf_predictions <- predict(rf_model, students, type = "class")

confusionMatrix(rf_predictions, students$Pass_Fail, positive = "Pass")
```
## ROC Curve and AUC
```{r}
library(pROC)

rf_probs <- predict(rf_model, students, type = "prob")[,2]

rf_roc <- roc(students$Pass_Fail, rf_probs)
plot(rf_roc, main="ROC Curve - Random Forest", col="darkgreen", lwd=2)
auc(rf_roc)
```
MODEL COMPARISON: Logistic Regression vs Random Forest

**Logistic Regression**(Attendance Only)
AUC(ROC): 0.798
Sensitivity (Pass Recall):59.95%
Specificity (Fail Recall): 81.3%
Balanced Accuracy: 70.62%
Interpretability: Very high (single coefficient: Attendance)

**Random Forest**(Multiple Features)
AUC(ROC): ~0.8772 
Sensitivity (Pass Recall): 92.93%
Specificity (Fail Recall): 44.44% (lower than logistic regression)
Balanced Accuracy : 68.69%
Accuracy : 76.72%

Most Important Feature : Attendance (confirmed by variable importance plot)

**CONCLUSION**
Logistic Regression gives balanced performance and is easier to interpret, especially useful if decision-makers want clear, actionable thresholds.
Random Forest is more powerful at detecting students likely to pass, but it sacrifices specificity â€” it struggles more with correctly identifying who might fail.


